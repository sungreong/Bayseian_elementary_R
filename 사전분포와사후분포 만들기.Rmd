---
title: "Probability Distribution"
author: "Taewook Lee"
date: ''
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    fig_height: 6
    fig_width: 10
    highlight: tango
    number_sections: yes
    theme: united
    toc: yes
    toc_float: no
  word_document:
    toc: yes
---


# 이항분포에 대한 베이지안 추론

<br>

## 이항비율의 추정 ex)5.1

* 새로운 교육방법이 효과가 있는지 알아보기 위하여 40명의 어린이들을 표본으로 삼아 조사하고자 한다. 변수 $X_i$ 를 $i$번째 어린이에게 효과가 있었으면, 1 아니면 0 값을 갖는다고 정의한다. 어떤 어린이를 먼저 조사하고 어떤 어린이를 나중에 조사하는지 상관이 없다면, 즉 어린이들을 조사하는 순서를 어떻게 하든 상관이 없다면, 자료 $X_1,...X_{40}$은 교환 가능성을 지니므로 De Finetti 정리에 의하여 $X_1,...,X_n$이 갖고 있는 정보를 당므과 같이 나누어 생각 할 수 있다.

* $\theta = \lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^{n} x_i$

* $\theta$가주어졌을 때 $X_i$들은 조건부 독립이며, 각 $i$에 대하여 $X_i = 1$일 확률은 $\theta$ 이다

* $f(x_1,...,x_{40} | \theta)=\theta^{\sum_{i=1}^{40} x_i}(1-\theta)^{40-\sum_{i=1}^{40} x_i}$

* 사후분포는 $Beta(16,26)$ 분포이다. 

 $$Mode(\theta | X_1 , ... , X_{40}) = \frac{15}{15+25} = 0.375$$

 $$E(\theta | X_1 , ... , X_{40}) = \frac{16}{16+26} = 0.381$$

 $$Var(\theta | X_1 , ... , X_{40}) = \frac{16\times26}{(16+26+1)(16+26)^2} = 0.375$$

```{r}
# theta ~ Beta(a,b)

a <- 1 ; b <- 1
# X ~ B(n,theta)
n <- 40; x <- 15

# a discretization of the possible theta values
theta <- seq(0,1,length=50)
prior.theta <- dbeta(theta,a,b) # prior
# prob of data|theta(likelihood)
linkd.theta <- dbinom(x,n,theta)
#joint prob of data $ theta
joint.xtheta <- prior.theta*linkd.theta
post.theta <-  dbeta(theta, a+x, b+n-x) # posterior of theta

par(mfrow=c(2,2)) # set up a 2x2 plotting window
plot(theta,prior.theta,type="l")
abline(v=(a-1)/(a-1+b-1), lty=2) # a vertical line at mode
mtext("prior : p(theta)", side=3)

plot(theta, linkd.theta, type="l")
abline(v=x/n, lty=2)
mtext("likelihood : p(x|theta)",side=3)

plot(theta, joint.xtheta , type="l")
abline(v= (a+x-1)/(a+b+n-2), lty=2)
mtext("prior x likelihood : p(theta) x p(x|theta)", side=3)

plot(theta, post.theta , type="l")
abline(v=(a+x-1)/(a+b+n-2),lty=2)
mtext("posterior : p(theta|x) ",side=3)
```

<br>

## 사전밀도함수와 사후밀도함수 같은 도면상에서 비교하기

* 사후분포는 자료 정보를 대입하여 사전정보를 개선시킨 것이라 볼 수 있다 하였는데, 그런 의미에서 사전밀도함수와 사후밀도함수를 같은 도면상에서 비교하는 것은 의미가 있다.

* 사후밀도함수는 0.375 최대로 뾰족한 형태를 취한 반면, 사전 밀도함수는 평평하다. 즉 사전정보는 어떤 특정한 $\theta$에 대하여 차별을 두지 않으나 사후 정보 $\theta$는 0.375에 가까운 값일 확률이 매우 높다는 정보를 우리에게 준다. 이 차이는 자료정보로부터 기인한 것으로 40개의 자료중에서 15개가 성공이라는 정보가 추가됨으로써 발생한 것이다.

```{r}
par(mfrow=c(1,1))
plot(theta, post.theta , type="l", col="blue")
lines(theta, prior.theta, col="red", lty=2)

legend(.5 , 3, legend =c(paste("beta(",a,",",b,") prior"), 
                         paste("post under beta(",a,",",b,") prior")),lty=c(2,1),
       col=c("red","blue"),bty="n") 

```

<br>

## monte carlo method

* 위의 경우의 사후분포는 수리적 형태로 주어진 경우로 사후평균, 사후분산을 구하고 밀도함수를 그리는데 문제가 없지만, 밀도함수식이 수리적으로 주어지지 않거나 유도가 복잡하거나, 수하평균, 분산등을 구하기 어렵지만 사후분포로부터 표본을 생성하는 것은 가능한 경우가 있다. 이때 이 표본을 바탕으로 사후추정치나 사후밀도함수를 근사적으로 구할 수 있다. 즉 시뮬레이션을 통하여 사후추정치나 사후밀도함수를 구하는 것인데 이러한 방법을 몬테칼로 방법이라 부른다.


```{r}
# simulation-based inference
# theta ~ Beta(a,b)

a <- 1 ; b <- 1  ; n <- 40; x <- 15
theta <-  rbeta(2000,a+x,b+n-x)
hist(theta, prob=T ,main="Histogram of theta")
lines(density(theta))
mean.theta <- mean(theta)
abline(v=mean.theta,lty=2)
quantile(theta,c(0.025, 0.975)) # simulation-based quantiles
qbeta(c(.025, 0.975),a+x,b+n-x) # theoretical quantiles

# simulation-based estimates
mean(theta) ; var(theta)
#theoritical estimate
(a+x)/(a+b+n) ; (a+x)*(b+n-x) /((a+b+n+1)*(a+b+n)^2)
```

<br>

## monte carlo method_eta estimation

* 위의 값을 확인해보면 큰 차이가 없는 것을 확인 할 수 있다. 만약 표본을 더 크게 한다면 보다 더 정확하게 표본으로부터 사후평균, 분산, 그리고 사후밀도함수를 추정 할 수 있을 것이다.

* 이항분포에서 성공확률 $\theta$ 대신에 로그 오즈비 $\eta=log(\frac{\theta}{1-\theta})$의 추론에 관심이 있다고 하자. $\eta$의 사후 밀도함수나 사후평균 등은 수리적 유도가 복잡하나 $\eta$의 표본 생성은 매우 간단하다. $\theta$의 표본을 생성하여 $\eta=log(\frac{\theta}{1-\theta})$ 변환을 하면 $\eta$에 대한 표본을 얻게 되는 것이다. $\eta_i = log(\frac{\theta_i}{1-\theta_i})$을 통하여 얻어진다. 

```{r,warning=FALSE}
a <- 1 ; b <- 1  ; n <- 40; x <- 15
theta = rbeta(10000, a+x, b+n-x)
eta <- log(theta/(1-theta))
hist(eta, prob=T, main="Histogram of eta")
lines(density(eta),lty=2)
```
<br>
      
## Beta 사전분포와 이항분포의 성공 확률에 대한 공액사전분포(conjugate prior)

 $$X|\theta ~ B(n, \theta) , \theta ~ Beta(a,b)  ==> \theta|x ~ Beta(x+a, n-x+b)$$

* Beta(2,10) ==> Beta(2+15,10+25) == > 추가적인 10번 시행 Beta(17+5, 35+5)

* 그림이 점점 오른쪽으로 이동하게 된다.

```{r}

theta <-  seq(0,1, length=50)
a <- 2 ; b <- 10 ; x <- 15 ; n <- 40 ; z <- 5 ; m <- 5
prior.theta <- dbeta(theta,a,b)
post.theta <- dbeta(theta, a+x , b+n-x)
post2.theta <- dbeta(theta,a+x+z , b+n-x+m-z)
plot(theta, post.theta, type="l", col="blue")
lines(theta,post2.theta, lty=2, col="black")
lines(theta,prior.theta, lty=3, col="red")
legend(.5,3, legend=c(paste("beta(",a,",",b,") prior") , 
                      paste("beta(",a+x+z,",",b+n-x+m-z,") posterior")) ,
       lty=c(3,1,2), col=c("red","blue","black"), bty="n")


```

<br>

## 예측분포 ex)5.3

* 베이즈안 추론의 중요한 특징 중 하나는 미래의 관측값에 대한 예측분포를 모수의 추정값에 의존하지않고 단지 이전의 자료에만 의존하여 구할 수 있다는 것이다.

*  ex)5.1 에서 균일사전분포를 가정 할때 현 시점 이후로 10번의 시행 중 성공횟수 z에 대한 예측분포
그림을 보면 10번의 시행 중 3번 혹은 4번 성공할 확률이 높음을 알 수 있다. 위의 예측분포에서 z의 예측평균을 구해보면 3.8095 예측분산 2.8558  고전적 최우추정법에 의한 예측을 살펴보면

* $P(Z = z | \hat{\theta}= 0.375) = \binom{10}{z}0.375^{z}(1-0.375)^{10-z} ,z = 0,...,10$이며 z의 예측평균 3.75이고 예측분산은 2.3438이다. 베이지안 예측평균은 3.8095가 고전적 예측평균 3.75보다 약간 중심이 이동한 것을 알 수 있는데, 이는 균일 사전 분포의 평균 0.5의 영향 때문이다.

* 예측분산을 비교해보면 고전적 예측분산 2.3438이 베이지안 예측분산 2.8558보다 작음을 볼 수 있는데, 이는 베이지안 예측에서는 $\theta$의 변동성을 고려한 반면 고전적 예측에서는 \hat{\theta}을 추정할 때의 오차를 고려하지 않았기 때문이다. 이는 고전적 예측에서는 예측분산을 작게 추정하는(underestimate) 문제가 있음을 보여준다.

<br>    

$$\frac{\Gamma(m+1)}{\Gamma(z+1)\Gamma(m-z+1)}\times\frac{Beta(a+z+x,  b+n-x+m-z)}{Beta(a+x,  b+n-x)}$$


```{r}
## 예측분포
a <- 1; b <- 1 ; n <- 40 ; x <- 15 ;
m <- 10 ; z <- c(0:10)

pred.z <- gamma(m+1) /gamma(z+1) / gamma(m-z+1)*beta(a+z+x,b+n-x+m-z) /beta(a+x, b+n-x)

plot(z, pred.z, xlab="z", ylab ="probability",type="h")
title("Predictive Distribution , a=1, b=1, n=40,x=15,m=10")

## 몬테칼로 추정치로 이용한 예측분포
a <- 1; b <- 1 ; n <- 40 ; x <- 15 ;
m <- 10 ; N <- 10000
theta <- c(1:N)
Z <- c(1:N)
for (i in 1:N){
  theta[i] <- rbeta(1,a+x, b+n-x)
  z[i] <- rbinom(1,m,theta[i])
}
plot(table(z)/N ,type="h", xlab="z",ylab="predictive density",main="몬테칼로 추정치")
mean(z)
var(z)
```

<br>

## 5.3 베이지안 신뢰구간

<br>

* $\theta$의 사전분포를 균일분포로 가정하고 이항 관측치로, n=10, x=2 가 얻어졌을 때, $\theta$의 베이진 신뢰구간을 구해보자. 이 경우 수리적으로는 구하기 어려우므로 누적확률 2.5% 와 97.5%에 해당하는 구간을 대략적인 최대사후구간이라고 하자. 비교를 위해 고전적 95%신뢰구간을 점선으로 표시한다.

* 두 신뢰구간을 비교하면 균일분포를 사용햇음에도 불구하고 베이지안 신뢰구간이 고전적 신뢰구간보다 길이가 짧음을 알수 있다. 이는 베이지안을 사용했을 때 베이지안 사후분포 Beta(x+1,n-x+1)로, 성공과 실패의 각 1 을 더한 효과를 주기 때문이다. 이렇듯 관찰횟수에 1을 더하는 효과는 극단적인 값, 예를들어 x=0, x=n이 관측되는 경우, 고정통계에서 $\theta$의 추정치로 변방값이 0또는 1을 선택하는 문제를 피할 수 있다.

* x=0, x=n 의 극단적인 값이 관측되는 경우는 보통 자료의수가 작은 경우인데, 베이지안 추정은 이때의 자료의 영향으로 희석시키는 효과가 있다. 성공과 실패 횟수에 1보다 더 작은 수를 더하고 싶으면, 균일사전분포 대신 작은 값 $\epsilon$에 대하여 $Beta(\epsilon,\epsilon)$ 사전분포를 가정하여, 성공과 실패 횟수에 각각에 $\epsilon$을 더하는 효과를 가질 수 있다.


```{r}

a <- 1 ; b <- 1; n <- 10 ; x <- 2 ;
theta <- seq(0,1,0.01)
plot(theta, dbeta(theta,a+x,b+n-x), type="l", ylab="p(theta|x)")
abline(v=qbeta(c(0.025,0.975),a+x,b+n-x))
abline(v=c(0.025,0.56),lty=2)
legend(.55, 1.5, legend=c(paste("Bayseian intervel"), paste("Classical intervel")), lty=c(1,2),bty="n")

```

<br>

## 예제 4-2

* 한 회사에서 새로운 상품을 개발하여 시장에 선을 보이려고 한다. 이 신상품이 히트 상품이 될 것인지 궁금하다. 시상품의 실제 시장 점유율을 p라 하자. 이 회사는 무작위로 선정한 5명의 소비자에게 개발한 상품을 소개한 후 새로운 상품의 구매 희망 여부를 물어 보려고 한다. 이 조사를 통해 얻게 될 신상품의 점유율의 p의 사후분포를 구하여라

* (풀이) 5명의 소비자 중 새로운 상품을 선택한 소비자의 수를 X라 하면, X는 이항 분포 B(5,p)을 따르는 확률변수가 된다. 따라서 우도함수는 $l(x|p)=p^{x}(1-p)^{5-x}, x= 0,1,2,3,4,5$이다. 사전밀도함수는 이렇게 가정하자  $\phi(p) = 2(1-p), 0<p<1$ 그래서 사후분포는 $h(p|X=x) ~ Beta(x+1, 7-x)$가 된다. 


```{r}
p <- seq(from=0,to=1,by=0.01)
par(mfrow=c(2,3))
x <- 0
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=0)")
lines(p,2*(1-p),lty=2)
x <- 1
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=1)")
lines(p,2*(1-p),lty=2)
x <- 2
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=2)")
lines(p,2*(1-p),lty=2)
x <- 3
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=3)")
lines(p,2*(1-p),lty=2)
x <- 4
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=4)")
lines(p,2*(1-p),lty=2)
x <- 5
plot(p, dbeta(p,x+1,7-x), type="l",xlab="p",ylab="",main="h(p|x=5)")
lines(p,2*(1-p),lty=2)

```

<br>

## 공액사전분포

![table](C:\Users\PC\Desktop\conjugate table.PNG)

사전밀도함수 $\theta$ ~ $Gamma(\alpha, \beta)$ , $p(x|\theta)$ ~ $poi(\theta)$  ==> 사후밀도함수 $P(\theta |x)$ ~ $Gamma(n\bar{x}+\alpha, \frac{1}{n+\frac{1}{\beta}})$
```{r}

theta <- 2
n <- 10; x <- rpois(n, theta)
x

alpha <- 3 ; beta <- 2 # 사전분포 모수값 
z <- seq(from=0,to=10,by=0.01)
plot(z,dgamma(z,shape=alpha, scale=beta) ,type="l" ,xlab="",ylab="", ylim=c(0,1),lwd=2,lty=1) # 사전분포 그래프
alpha <- sum(x) + alpha
beta <- 1/(n+1/beta)
lines(z,dgamma(z,shape=alpha,scale=beta),lty=2, lwd=3, col=2)# 사후분포 그래프 
title("Prior vs. Posterior")

```
<br>




